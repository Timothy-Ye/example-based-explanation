{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from influence.influence_model import InfluenceModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the MNIST dataset, consisting of images of handwritten digits, and their respective labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_dataset = tf.keras.datasets.mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist_dataset.load_data()\n",
    "\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0\n",
    "\n",
    "categorical_train_labels = tf.keras.utils.to_categorical(train_labels)\n",
    "categorical_test_labels = tf.keras.utils.to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "for i in range(10):\n",
    "    plt.subplot(1, 10, i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(train_images[i], cmap=plt.cm.binary)\n",
    "    plt.xlabel(train_labels[i])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use a logistic regression model to classify each image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.set_floatx('float64')\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28,28)),\n",
    "    tf.keras.layers.Dense(10, kernel_regularizer='l2', bias_regularizer='l2')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note: As Scipy uses float64 by default, running our model in float64 saves time by reducing need for casting.*\n",
    "\n",
    "*Note: Auto-differentiation is not supported for tf.keras.losses.SparseCategoricalCrossentropy(), hence we use tf.keras.losses.CategoricalCrossentropy() instead, and we have processed our labels as needed.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/10\n",
      "54000/54000 [==============================] - 6s 119us/sample - loss: 0.7892 - accuracy: 0.8585 - val_loss: 0.6235 - val_accuracy: 0.9072\n",
      "Epoch 2/10\n",
      "54000/54000 [==============================] - 6s 105us/sample - loss: 0.6942 - accuracy: 0.8855 - val_loss: 0.6234 - val_accuracy: 0.9108\n",
      "Epoch 3/10\n",
      "54000/54000 [==============================] - 6s 102us/sample - loss: 0.6945 - accuracy: 0.8858 - val_loss: 0.6285 - val_accuracy: 0.9090\n",
      "Epoch 4/10\n",
      "54000/54000 [==============================] - 6s 102us/sample - loss: 0.6939 - accuracy: 0.8863 - val_loss: 0.6213 - val_accuracy: 0.9117\n",
      "Epoch 5/10\n",
      "54000/54000 [==============================] - 6s 103us/sample - loss: 0.6945 - accuracy: 0.8849 - val_loss: 0.6242 - val_accuracy: 0.9115\n",
      "Epoch 6/10\n",
      "54000/54000 [==============================] - 5s 101us/sample - loss: 0.6949 - accuracy: 0.8847 - val_loss: 0.6265 - val_accuracy: 0.9133\n",
      "Epoch 7/10\n",
      "54000/54000 [==============================] - 6s 104us/sample - loss: 0.6941 - accuracy: 0.8849 - val_loss: 0.6229 - val_accuracy: 0.9100\n",
      "Epoch 8/10\n",
      "54000/54000 [==============================] - 6s 106us/sample - loss: 0.6944 - accuracy: 0.8845 - val_loss: 0.6239 - val_accuracy: 0.9138\n",
      "Epoch 9/10\n",
      "54000/54000 [==============================] - 6s 105us/sample - loss: 0.6943 - accuracy: 0.8848 - val_loss: 0.6280 - val_accuracy: 0.9102\n",
      "Epoch 10/10\n",
      "54000/54000 [==============================] - 6s 106us/sample - loss: 0.6937 - accuracy: 0.8854 - val_loss: 0.6219 - val_accuracy: 0.9128\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1e008fa3248>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    train_images,\n",
    "    categorical_train_labels,\n",
    "    epochs=10,\n",
    "    validation_split=0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating inverse HVP using Conjugate Gradient method:\n",
      "Current error: 4.539898843434823 , Relative error: 0.6540244698030632\n",
      "Current error: 6.958545621541236 , Relative error: 1.0024582634281047\n",
      "Current error: 1.5025391941455872 , Relative error: 0.21645799470410546\n",
      "Current error: 1.1594706099925718 , Relative error: 0.1670350325204361\n",
      "Current error: 1.2568639881735268 , Relative error: 0.18106566507940644\n",
      "Current error: 0.49576814000317043 , Relative error: 0.07142108361725204\n",
      "Current error: 0.3617989344115435 , Relative error: 0.05212128384666729\n",
      "Current error: 0.2787610411255575 , Relative error: 0.040158723445466574\n",
      "Current error: 0.13800081177993445 , Relative error: 0.019880598856796907\n",
      "Current error: 0.1150232159181661 , Relative error: 0.016570412777965202\n",
      "Current error: 0.10296123515515135 , Relative error: 0.014832746181117223\n",
      "Current error: 0.05428269813556518 , Relative error: 0.007820044915523332\n",
      "Current error: 0.03818745730862594 , Relative error: 0.0055013409727219945\n",
      "Current error: 0.040513020014129895 , Relative error: 0.0058363649386547365\n",
      "Current error: 0.014996522150391918 , Relative error: 0.002160420922700406\n",
      "Current error: 0.013321839470991144 , Relative error: 0.0019191636856438225\n",
      "Current error: 0.008487779180107556 , Relative error: 0.0012227618873277256\n",
      "Current error: 0.0062626580211812485 , Relative error: 0.0009022076775530186\n",
      "Current error: 0.004842349386220534 , Relative error: 0.0006975959375182805\n",
      "Current error: 0.0029384115727138704 , Relative error: 0.0004233118704145779\n",
      "Current error: 0.0018935344132701853 , Relative error: 0.00027278533804421024\n",
      "Current error: 0.0028618995137040704 , Relative error: 0.0004122894312472847\n",
      "Current error: 0.001603192924589996 , Relative error: 0.0002309583183804363\n",
      "Current error: 0.0012035366529843392 , Relative error: 0.0001733832511477491\n",
      "Current error: 0.0010808505909029767 , Relative error: 0.00015570891753984858\n",
      "Current error: 0.0003222060226372664 , Relative error: 4.641747104727473e-05\n",
      "Current error: 0.0002922715701707047 , Relative error: 4.2105070027238854e-05\n",
      "Current error: 0.0001843968538162886 , Relative error: 2.6564480555541803e-05\n",
      "Current error: 0.00012339875436825397 , Relative error: 1.777700510150461e-05\n",
      "Current error: 0.00011238067388662684 , Relative error: 1.618972430654495e-05\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -90.944431\n",
      "         Iterations: 30\n",
      "         Function evaluations: 43\n",
      "         Gradient evaluations: 43\n",
      "Wall time: 29 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-0.08112733098883013"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "influence_model = InfluenceModel(\n",
    "    model,\n",
    "    train_images,\n",
    "    categorical_train_labels,\n",
    "    model.loss,\n",
    "    0,\n",
    "    damping=0.1,\n",
    "    dtype=np.float64,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "influence_model.get_influence_on_loss(\n",
    "    test_images[0],\n",
    "    categorical_test_labels[0]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating inverse HVP using Conjugate Gradient method:\n",
      "Current error: 4.539898843434823 , Relative error: 0.6540244698030632\n",
      "Current error: 6.958545621541236 , Relative error: 1.0024582634281047\n",
      "Current error: 1.5025391941455872 , Relative error: 0.21645799470410546\n",
      "Current error: 1.1594706099925718 , Relative error: 0.1670350325204361\n",
      "Current error: 1.2568639881735268 , Relative error: 0.18106566507940644\n",
      "Current error: 0.49576814000317043 , Relative error: 0.07142108361725204\n",
      "Current error: 0.3617989344115435 , Relative error: 0.05212128384666729\n",
      "Current error: 0.2787610411255575 , Relative error: 0.040158723445466574\n",
      "Current error: 0.13800081177993445 , Relative error: 0.019880598856796907\n",
      "Current error: 0.1150232159181661 , Relative error: 0.016570412777965202\n",
      "Current error: 0.10296123515515135 , Relative error: 0.014832746181117223\n",
      "Current error: 0.05428269813556518 , Relative error: 0.007820044915523332\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -90.941817\n",
      "         Iterations: 12\n",
      "         Function evaluations: 22\n",
      "         Gradient evaluations: 22\n",
      "Wall time: 13.9 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-0.07672681223332037"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "influence_model = InfluenceModel(\n",
    "    model,\n",
    "    train_images,\n",
    "    categorical_train_labels,\n",
    "    model.loss,\n",
    "    0,\n",
    "    damping=0.1,\n",
    "    dtype=np.float64,\n",
    "    verbose=True,\n",
    "    cg_tol=1e-02\n",
    ")\n",
    "\n",
    "influence_model.get_influence_on_loss(\n",
    "    test_images[0],\n",
    "    categorical_test_labels[0]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating inverse HVP using LiSSA method:\n",
      "Sample 1 with depth 500 - Current error: 0.04062685116835949 , Relative error: 0.5852763752101179\n",
      "Sample 2 with depth 500 - Current error: 0.041336604361159573 , Relative error: 0.5955011837795636\n",
      "Overall error: 0.039850383019833555 , Overall relative error: 0.574090461205803\n",
      "Wall time: 16 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-0.05627619461906666"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "influence_model = InfluenceModel(\n",
    "    model,\n",
    "    train_images,\n",
    "    categorical_train_labels,\n",
    "    model.loss,\n",
    "    0,\n",
    "    dtype=np.float64,\n",
    "    verbose=True,\n",
    "    method='lissa',\n",
    "    scaling=0.01,\n",
    "    lissa_samples=2,\n",
    "    lissa_depth=500\n",
    ")\n",
    "\n",
    "influence_model.get_influence_on_loss(\n",
    "    test_images[0],\n",
    "    categorical_test_labels[0]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating inverse HVP using LiSSA method:\n",
      "Sample 1 with depth 1000 - Current error: 0.06468555262149593 , Relative error: 0.9318695561682443\n",
      "Overall error: 0.06468555262149593 , Overall relative error: 0.9318695561682443\n",
      "Wall time: 16.1 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-0.06447038857042435"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "influence_model = InfluenceModel(\n",
    "    model,\n",
    "    train_images,\n",
    "    categorical_train_labels,\n",
    "    model.loss,\n",
    "    0,\n",
    "    dtype=np.float64,\n",
    "    verbose=True,\n",
    "    method='lissa',\n",
    "    scaling=0.01,\n",
    "    lissa_samples=1,\n",
    "    lissa_depth=1000\n",
    ")\n",
    "\n",
    "influence_model.get_influence_on_loss(\n",
    "    test_images[0],\n",
    "    categorical_test_labels[0]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.experimental.list_physical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
