{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import influence.core\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 3s 50us/sample - loss: 0.9651 - accuracy: 0.7897\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 0.8549 - accuracy: 0.8061\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 2s 40us/sample - loss: 0.8484 - accuracy: 0.8087\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 2s 40us/sample - loss: 0.8445 - accuracy: 0.8119\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 2s 41us/sample - loss: 0.8455 - accuracy: 0.8106\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 3s 45us/sample - loss: 0.8443 - accuracy: 0.8104\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 2s 40us/sample - loss: 0.8431 - accuracy: 0.8112\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 2s 38us/sample - loss: 0.8426 - accuracy: 0.8129\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 2s 41us/sample - loss: 0.8410 - accuracy: 0.8132\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 2s 39us/sample - loss: 0.8414 - accuracy: 0.8129\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x236f29e80c8>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Simple Keras model for MNIST Fashion Dataset, based on TensorFlow tutorials.\n",
    "\n",
    "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
    "\n",
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0\n",
    "\n",
    "train_labels = tf.keras.utils.to_categorical(train_labels)\n",
    "test_labels = tf.keras.utils.to_categorical(test_labels)\n",
    "\n",
    "tf.keras.backend.set_floatx('float64')\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    tf.keras.layers.Dense(32, activation='relu', kernel_regularizer='l2', bias_regularizer='l2'),\n",
    "    tf.keras.layers.Dense(10, kernel_regularizer='l2', bias_regularizer='l2')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_images, train_labels, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_theta_relatif(\n",
    "    model,\n",
    "    training_samples,\n",
    "    training_labels,\n",
    "    training_sample,\n",
    "    training_label,\n",
    "    test_sample,\n",
    "    test_label,\n",
    "    loss_fn=None,\n",
    "    scaling=1.0,\n",
    "    damping=0.0,\n",
    "    verbose=False\n",
    "):\n",
    "    \n",
    "    if loss_fn is None:\n",
    "        loss_fn = model.loss\n",
    "\n",
    "    training_gradient = influence.core.get_training_gradient(\n",
    "        model, training_sample, training_label, loss_fn, scaling\n",
    "    )\n",
    "\n",
    "    test_gradient = influence.core.get_test_gradient(model, test_sample, test_label, loss_fn)\n",
    "    flat_test_gradient = np.concatenate([tf.reshape(t, [-1]) for t in test_gradient])\n",
    "\n",
    "    inverse_hvp = influence.core.get_inverse_hvp_cg(\n",
    "        model,\n",
    "        training_samples,\n",
    "        training_labels,\n",
    "        loss_fn,\n",
    "        scaling,\n",
    "        damping,\n",
    "        training_gradient,\n",
    "        verbose,\n",
    "    )\n",
    "    \n",
    "    influence_value = np.dot(inverse_hvp, flat_test_gradient)\n",
    "    \n",
    "    theta_scaling = np.linalg.norm(inverse_hvp)    \n",
    "    theta_relatif = influence_value / theta_scaling\n",
    "    \n",
    "    return theta_relatif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CG Loss:  -0.000872628577375077 ; CG Jac Norm: 0.004958180685066728\n",
      "CG Loss:  -0.0011397608923423728 ; CG Jac Norm: 0.004738394938580228\n",
      "CG Loss:  -0.0013116379733708076 ; CG Jac Norm: 0.0038058650319041467\n",
      "CG Loss:  -0.0014517740141695796 ; CG Jac Norm: 0.002168127419231557\n",
      "CG Loss:  -0.001467367947740386 ; CG Jac Norm: 0.0009442666696747254\n",
      "CG Loss:  -0.0014758699950389953 ; CG Jac Norm: 0.0009894392443723068\n",
      "CG Loss:  -0.0014814767302429167 ; CG Jac Norm: 0.0005709809970245365\n",
      "CG Loss:  -0.001484389065068644 ; CG Jac Norm: 0.00035911908103570807\n",
      "CG Loss:  -0.001485431309935835 ; CG Jac Norm: 0.0003159653864884112\n",
      "CG Loss:  -0.001486294539985127 ; CG Jac Norm: 0.0002351577845787752\n",
      "CG Loss:  -0.0014869894840064876 ; CG Jac Norm: 0.00012079156026295089\n",
      "CG Loss:  -0.0014871923606757488 ; CG Jac Norm: 7.192594207130669e-05\n",
      "CG Loss:  -0.0014872689878096662 ; CG Jac Norm: 7.581533109040235e-05\n",
      "CG Loss:  -0.0014873417405910452 ; CG Jac Norm: 7.90515099783566e-05\n",
      "CG Loss:  -0.0014873990126935937 ; CG Jac Norm: 5.895821851278571e-05\n",
      "CG Loss:  -0.0014874177537619582 ; CG Jac Norm: 4.43956276420671e-05\n",
      "CG Loss:  -0.0014874402473034607 ; CG Jac Norm: 2.9634414756594786e-05\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -0.001487\n",
      "         Iterations: 17\n",
      "         Function evaluations: 51\n",
      "         Gradient evaluations: 51\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.2117499769807654"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_theta_relatif(\n",
    "    model,\n",
    "    train_images,\n",
    "    train_labels,\n",
    "    train_images[0:1],\n",
    "    train_labels[0:1],\n",
    "    test_images[0:1],\n",
    "    test_labels[0:1],\n",
    "    scaling=0.01,\n",
    "    damping=0.01,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_l_relatif(\n",
    "    model,\n",
    "    training_samples,\n",
    "    training_labels,\n",
    "    training_sample,\n",
    "    training_label,\n",
    "    test_sample,\n",
    "    test_label,\n",
    "    loss_fn=None,\n",
    "    scaling=1.0,\n",
    "    damping=0.0,\n",
    "    verbose=False\n",
    "):\n",
    "    \n",
    "    if loss_fn is None:\n",
    "        loss_fn = model.loss\n",
    "\n",
    "    training_gradient = influence.core.get_training_gradient(\n",
    "        model, training_sample, training_label, loss_fn, scaling\n",
    "    )\n",
    "    flat_training_gradient = np.concatenate([tf.reshape(t, [-1]) for t in training_gradient])\n",
    "\n",
    "    test_gradient = influence.core.get_test_gradient(model, test_sample, test_label, loss_fn)\n",
    "    flat_test_gradient = np.concatenate([tf.reshape(t, [-1]) for t in test_gradient])\n",
    "\n",
    "    inverse_hvp = influence.core.get_inverse_hvp_cg(\n",
    "        model,\n",
    "        training_samples,\n",
    "        training_labels,\n",
    "        loss_fn,\n",
    "        scaling,\n",
    "        damping,\n",
    "        training_gradient,\n",
    "        verbose,\n",
    "    )\n",
    "    \n",
    "    influence_value = np.dot(inverse_hvp, flat_test_gradient)\n",
    "    \n",
    "    l_scaling = sqrt(np.dot(inverse_hvp, flat_training_gradient))\n",
    "    l_relatif = influence_value / l_scaling\n",
    "    \n",
    "    return l_relatif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CG Loss:  -0.000872628577375077 ; CG Jac Norm: 0.004958180685066728\n",
      "CG Loss:  -0.0011397608923423728 ; CG Jac Norm: 0.004738394938580228\n",
      "CG Loss:  -0.0013116379733708076 ; CG Jac Norm: 0.0038058650319041467\n",
      "CG Loss:  -0.0014517740141695796 ; CG Jac Norm: 0.002168127419231557\n",
      "CG Loss:  -0.001467367947740386 ; CG Jac Norm: 0.0009442666696747254\n",
      "CG Loss:  -0.0014758699950389953 ; CG Jac Norm: 0.0009894392443723068\n",
      "CG Loss:  -0.0014814767302429167 ; CG Jac Norm: 0.0005709809970245365\n",
      "CG Loss:  -0.001484389065068644 ; CG Jac Norm: 0.00035911908103570807\n",
      "CG Loss:  -0.001485431309935835 ; CG Jac Norm: 0.0003159653864884112\n",
      "CG Loss:  -0.001486294539985127 ; CG Jac Norm: 0.0002351577845787752\n",
      "CG Loss:  -0.0014869894840064876 ; CG Jac Norm: 0.00012079156026295089\n",
      "CG Loss:  -0.0014871923606757488 ; CG Jac Norm: 7.192594207130669e-05\n",
      "CG Loss:  -0.0014872689878096662 ; CG Jac Norm: 7.581533109040235e-05\n",
      "CG Loss:  -0.0014873417405910452 ; CG Jac Norm: 7.90515099783566e-05\n",
      "CG Loss:  -0.0014873990126935937 ; CG Jac Norm: 5.895821851278571e-05\n",
      "CG Loss:  -0.0014874177537619582 ; CG Jac Norm: 4.43956276420671e-05\n",
      "CG Loss:  -0.0014874402473034607 ; CG Jac Norm: 2.9634414756594786e-05\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -0.001487\n",
      "         Iterations: 17\n",
      "         Function evaluations: 51\n",
      "         Gradient evaluations: 51\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "16.48598550063281"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_l_relatif(\n",
    "    model,\n",
    "    train_images,\n",
    "    train_labels,\n",
    "    train_images[0:1],\n",
    "    train_labels[0:1],\n",
    "    test_images[0:1],\n",
    "    test_labels[0:1],\n",
    "    scaling=0.01,\n",
    "    damping=0.01,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
